{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Profiling decorrelation and node perturbation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from node_perturbation.node_perturbation import NPLinear\n",
    "from node_perturbation.utils import np_train\n",
    "from decorrelation.utils import decor_train\n",
    "from decorrelation.decorrelation import Decorrelation, DecorLinear\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "\n",
    "import cProfile\n",
    "import pstats\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the effect of decprrelating after larger intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Profiling node perturbation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  \ttime:0.000 s\tbp loss: 5.198018\tdecorrelation loss: 6.596981\n",
      "epoch 1  \ttime:0.658 s\tbp loss: 5.074780\tdecorrelation loss: 2.382838\n",
      "epoch 2  \ttime:0.668 s\tbp loss: 5.007250\tdecorrelation loss: 0.513329\n",
      "epoch 3  \ttime:0.662 s\tbp loss: 4.983179\tdecorrelation loss: 0.261576\n",
      "Wed Mar 13 14:21:15 2024    restats\n",
      "\n",
      "         564699 function calls (559649 primitive calls) in 2.296 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 306 to 10 due to restriction <10>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000    2.296    2.296 {built-in method builtins.exec}\n",
      "        1    0.000    0.000    2.296    2.296 <string>:1(<module>)\n",
      "        1    0.008    0.008    2.296    2.296 /Users/marcel.vangerven/Code/github/decorrelation/node_perturbation/utils.py:7(np_train)\n",
      "       45    0.001    0.000    1.298    0.029 /Users/marcel.vangerven/Code/github/decorrelation/decorrelation/decorrelation.py:14(decor_update)\n",
      "       45    1.275    0.028    1.298    0.029 /Users/marcel.vangerven/Code/github/decorrelation/decorrelation/decorrelation.py:82(update)\n",
      "       64    0.001    0.000    0.582    0.009 /Users/marcel.vangerven/Code/environments/pytorch/lib/python3.11/site-packages/torch/utils/data/dataloader.py:626(__next__)\n",
      "       64    0.004    0.000    0.575    0.009 /Users/marcel.vangerven/Code/environments/pytorch/lib/python3.11/site-packages/torch/utils/data/dataloader.py:673(_next_data)\n",
      "       60    0.000    0.000    0.568    0.009 /Users/marcel.vangerven/Code/environments/pytorch/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:46(fetch)\n",
      "       60    0.000    0.000    0.559    0.009 /Users/marcel.vangerven/Code/environments/pytorch/lib/python3.11/site-packages/torch/utils/data/dataset.py:393(__getitems__)\n",
      "       60    0.004    0.000    0.559    0.009 /Users/marcel.vangerven/Code/environments/pytorch/lib/python3.11/site-packages/torch/utils/data/dataset.py:399(<listcomp>)\n",
      "\n",
      "\n",
      "Wed Mar 13 14:21:15 2024    restats\n",
      "\n",
      "         564699 function calls (559649 primitive calls) in 2.296 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "   List reduced from 306 to 10 due to restriction <10>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "       45    1.275    0.028    1.298    0.029 /Users/marcel.vangerven/Code/github/decorrelation/decorrelation/decorrelation.py:82(update)\n",
      "      120    0.250    0.002    0.250    0.002 {built-in method torch._C._nn.linear}\n",
      "       15    0.065    0.004    0.072    0.005 /Users/marcel.vangerven/Code/github/decorrelation/decorrelation/decorrelation.py:124(loss)\n",
      "     3840    0.046    0.000    0.113    0.000 /Users/marcel.vangerven/Code/environments/pytorch/lib/python3.11/site-packages/torchvision/transforms/_functional_tensor.py:903(normalize)\n",
      "     3840    0.040    0.000    0.555    0.000 /Users/marcel.vangerven/Code/environments/pytorch/lib/python3.11/site-packages/torchvision/datasets/mnist.py:130(__getitem__)\n",
      "     3840    0.032    0.000    0.208    0.000 /Users/marcel.vangerven/Code/environments/pytorch/lib/python3.11/site-packages/torchvision/transforms/functional.py:126(to_tensor)\n",
      "     3840    0.026    0.000    0.026    0.000 {method 'div' of 'torch._C.TensorBase' objects}\n",
      "     7680    0.025    0.000    0.025    0.000 {built-in method torch.as_tensor}\n",
      "     7680    0.022    0.000    0.022    0.000 {method 'clone' of 'torch._C.TensorBase' objects}\n",
      "     4080    0.018    0.000    0.018    0.000 {method 'to' of 'torch._C.TensorBase' objects}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x10f973410>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = argparse.Namespace(lr=1e-4, decor_lr=1e-1, kappa=1e-2, epochs=3, full=True)\n",
    "lossfun = torch.nn.CrossEntropyLoss().to(device)\n",
    "sampler = torch.distributions.Distribution = torch.distributions.Normal(0.0, 1e-3)\n",
    "\n",
    "# model = NPLinear(784, 10, sampler=sampler, device=device)\n",
    "# model, L1, D, T = np_train(args, model, lossfun, train_loader, device)\n",
    "\n",
    "model = nn.Sequential(Decorrelation(784, decor_lr=args.decor_lr, kappa=args.kappa, full=args.full), NPLinear(784, 10, sampler=sampler, device=device))\n",
    "\n",
    "cProfile.run('np_train(args, model, lossfun, train_loader, device)', 'restats')\n",
    "p = pstats.Stats('restats')\n",
    "p.sort_stats('cumulative').print_stats(10)\n",
    "p.sort_stats('time').print_stats(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytroch profiling. See https://pytorch.org/tutorials/recipes/recipes/profiler_recipe.html for more examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2024-03-13 14:21:15 68950:9119183 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  \ttime:0.000 s\tbp loss: 5.074006\tdecorrelation loss: 6.577436\n",
      "epoch 1  \ttime:0.650 s\tbp loss: 4.999786\tdecorrelation loss: 2.381298\n",
      "epoch 2  \ttime:0.660 s\tbp loss: 4.955505\tdecorrelation loss: 0.510715\n",
      "epoch 3  \ttime:0.652 s\tbp loss: 4.917325\tdecorrelation loss: 0.261559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2024-03-13 14:21:18 68950:9119183 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2024-03-13 14:21:18 68950:9119183 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "args = argparse.Namespace(lr=1e-4, decor_lr=1e-1, kappa=1e-2, epochs=3, full=True)\n",
    "lossfun = torch.nn.CrossEntropyLoss().to(device)\n",
    "sampler = torch.distributions.Distribution = torch.distributions.Normal(0.0, 1e-3)\n",
    "\n",
    "model = nn.Sequential(Decorrelation(784, decor_lr=args.decor_lr, kappa=args.kappa, full=args.full), NPLinear(784, 10, sampler=sampler, device=device))\n",
    "\n",
    "with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "    with record_function(\"model_training\"):\n",
    "        np_train(args, model, lossfun, train_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                         model_training         2.67%      60.702ms       100.00%        2.274s        2.274s             1  \n",
      "                                           aten::matmul         0.04%       1.013ms        66.10%        1.503s       6.679ms           225  \n",
      "                                               aten::mm        66.06%        1.502s        66.06%        1.502s       6.675ms           225  \n",
      "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        16.32%     370.989ms        25.00%     568.347ms       8.880ms            64  \n",
      "                                           aten::linear         0.05%       1.174ms        10.87%     247.162ms       2.060ms           120  \n",
      "                                               aten::to         0.75%      17.143ms         2.50%      56.744ms       1.961us         28937  \n",
      "                                         aten::_to_copy         1.59%      36.174ms         2.00%      45.536ms       3.526us         12915  \n",
      "                                              aten::div         1.11%      25.220ms         1.77%      40.342ms       9.961us          4050  \n",
      "                                            aten::clone         1.03%      23.503ms         1.25%      28.438ms       3.618us          7860  \n",
      "                                               aten::eq         0.44%      10.024ms         1.20%      27.293ms       7.108us          3840  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 2.274s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  -------------------------------------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls                                 Input Shapes  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  -------------------------------------------  \n",
      "                                         model_training         2.67%      60.702ms       100.00%        2.274s        2.274s             1                                           []  \n",
      "                                           aten::matmul         0.02%     343.000us        45.31%        1.030s      22.892ms            45                     [[784, 784], [784, 784]]  \n",
      "                                               aten::mm        45.29%        1.030s        45.29%        1.030s      22.884ms            45                     [[784, 784], [784, 784]]  \n",
      "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        16.32%     370.989ms        25.00%     568.347ms       8.880ms            64                                           []  \n",
      "                                           aten::linear         0.02%     424.000us        10.56%     240.015ms       4.000ms            60                 [[128, 784], [784, 784], []]  \n",
      "                                           aten::matmul         0.01%     279.000us        10.51%     239.020ms       3.984ms            60                     [[128, 784], [784, 784]]  \n",
      "                                               aten::mm        10.50%     238.741ms        10.50%     238.741ms       3.979ms            60                     [[128, 784], [784, 784]]  \n",
      "                                           aten::matmul         0.01%     115.000us        10.14%     230.575ms       3.843ms            60                     [[784, 128], [128, 784]]  \n",
      "                                               aten::mm        10.14%     230.460ms        10.14%     230.460ms       3.841ms            60                     [[784, 128], [128, 784]]  \n",
      "                                               aten::to         0.53%      12.018ms         1.55%      35.216ms       2.714us         12975                         [[], [], [], [], []]  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  -------------------------------------------  \n",
      "Self CPU time total: 2.274s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof.key_averages(group_by_input_shape=True).table(sort_by=\"cpu_time_total\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
