{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyses properties of decorrelation and whitening methods for decorrelated networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from decorrelation.decorrelation import Decorrelation, DecorLinear, DecorConv2d\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from decorrelation.train import decor_train\n",
    "import argparse\n",
    "\n",
    "# automatic reloading of modules when they change\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Grayscale(1),\n",
    "        transforms.Normalize((0.5), (0.5))\n",
    "        ])\n",
    "\n",
    "train_data = MNIST(root='~/Data', train=True, download=True, transform=transform)    \n",
    "train_data = Subset(train_data, np.random.permutation(len(train_data.data))[:1000])\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True, num_workers=0, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  \ttime:0.000 s\tbp loss: 0.000000\tdecorrelation loss: 3.323010\n",
      "epoch 1  \ttime:0.537 s\tbp loss: 0.000000\tdecorrelation loss: 2.883162\n",
      "epoch 2  \ttime:0.546 s\tbp loss: 0.000000\tdecorrelation loss: 2.118621\n",
      "epoch 3  \ttime:0.536 s\tbp loss: 0.000000\tdecorrelation loss: 1.569368\n",
      "epoch 4  \ttime:0.531 s\tbp loss: 0.000000\tdecorrelation loss: 1.163987\n",
      "epoch 5  \ttime:0.533 s\tbp loss: 0.000000\tdecorrelation loss: 0.873308\n",
      "epoch 6  \ttime:0.537 s\tbp loss: 0.000000\tdecorrelation loss: 0.659124\n",
      "epoch 7  \ttime:0.530 s\tbp loss: 0.000000\tdecorrelation loss: 0.503914\n",
      "epoch 8  \ttime:0.531 s\tbp loss: 0.000000\tdecorrelation loss: 0.389484\n",
      "epoch 9  \ttime:0.529 s\tbp loss: 0.000000\tdecorrelation loss: 0.302870\n",
      "epoch 10 \ttime:0.529 s\tbp loss: 0.000000\tdecorrelation loss: 0.236460\n"
     ]
    }
   ],
   "source": [
    "model = Decorrelation(784, variance=1.0).to(device)\n",
    "\n",
    "lossfun = lambda x, y: nn.Parameter(torch.zeros(1, device=device, dtype=float), requires_grad=True)\n",
    "\n",
    "args = argparse.Namespace(lr=1e-4, eta=1e-5, epochs=10)\n",
    "\n",
    "res = decor_train(args, model, lossfun, train_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Sequential):\n",
    "    \"\"\"Simple MLP example\"\"\"\n",
    "\n",
    "    def __init__(self, in_features, variance):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            in_features: int, number of inputs\n",
    "            eta: float, decorrelation learning rate\n",
    "        \"\"\"\n",
    "        super().__init__(DecorLinear(in_features, 100, variance=variance),\n",
    "                        nn.ReLU(),\n",
    "                        DecorLinear(100, 10, variance=variance)\n",
    "                        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return super().forward(x.view(len(x), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  \ttime:0.000 s\tbp loss: 5.198516\tdecorrelation loss: 3.328140\n",
      "epoch 1  \ttime:0.579 s\tbp loss: 4.492834\tdecorrelation loss: 2.879488\n",
      "epoch 2  \ttime:0.564 s\tbp loss: 3.411903\tdecorrelation loss: 2.117524\n",
      "epoch 3  \ttime:0.554 s\tbp loss: 2.865552\tdecorrelation loss: 1.559836\n",
      "epoch 4  \ttime:0.552 s\tbp loss: 2.585968\tdecorrelation loss: 1.167807\n",
      "epoch 5  \ttime:0.547 s\tbp loss: 2.420695\tdecorrelation loss: 0.871845\n",
      "epoch 6  \ttime:0.547 s\tbp loss: 2.290833\tdecorrelation loss: 0.661645\n",
      "epoch 7  \ttime:0.550 s\tbp loss: 2.194351\tdecorrelation loss: 0.504670\n",
      "epoch 8  \ttime:0.549 s\tbp loss: 2.112690\tdecorrelation loss: 0.387976\n",
      "epoch 9  \ttime:0.550 s\tbp loss: 2.034244\tdecorrelation loss: 0.300150\n",
      "epoch 10 \ttime:0.548 s\tbp loss: 1.970677\tdecorrelation loss: 0.236579\n"
     ]
    }
   ],
   "source": [
    "model = MLP(784, variance=1.0).to(device)\n",
    "\n",
    "lossfun = torch.nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "args = argparse.Namespace(lr=1e-4, eta=1e-5, epochs=10)\n",
    "\n",
    "res = decor_train(args, model, lossfun, train_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
